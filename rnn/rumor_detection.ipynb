{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rumor Detection Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import helpers ## formatting data, and generate random sequence data\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.0-rc0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head of the batch:\n",
      "[6, 4, 6, 0, 7, 4]\n",
      "[5, 7, 2, 6, 5, 7, 9]\n",
      "[9, 7, 4, 2, 3, 0, 1, 8]\n",
      "[5, 1, 2, 2, 6, 3]\n",
      "[5, 8, 1, 4]\n",
      "[9, 3, 7, 1, 3]\n",
      "[0, 6, 1, 5]\n",
      "[1, 2, 7, 7, 8, 4]\n",
      "[6, 8, 1, 7, 0, 5]\n",
      "[5, 2, 6]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "batches = helpers.random_sequences(length_from=3, length_to=8,\n",
    "                                   vocab_lower=0, vocab_upper=10,\n",
    "                                   batch_size=batch_size)\n",
    "\n",
    "print('head of the batch:')\n",
    "for seq in next(batches)[:10]:\n",
    "    print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = 10\n",
    "input_embedding_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputs = tf.placeholder(shape=(batch_size, None), dtype=tf.int32, name='inputs')\n",
    "inputs_length = tf.placeholder(shape=(batch_size,), dtype=tf.int32, name='inputs_length')\n",
    "target_inputs = tf.placeholder(shape=(batch_size, None), dtype=tf.int32, name='target_inputs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings = tf.Variable(tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0), dtype=tf.float32)\n",
    "\n",
    "inputs_embedded = tf.nn.embedding_lookup(embeddings, inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow.contrib.rnn as rnn\n",
    "\n",
    "num_hidden_units = 20\n",
    "num_layers = 3\n",
    "\n",
    "cell = rnn.MultiRNNCell([rnn.ResidualWrapper(rnn.GRUCell(num_hidden_units)) for i in range(num_layers)])\n",
    "\n",
    "# cell = rnn.GRUCell(num_units=20)\n",
    "outputs, final_state = tf.nn.dynamic_rnn(cell,\n",
    "                                         inputs_embedded,\n",
    "                                         inputs_length,\n",
    "                                         cell.zero_state(batch_size, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rumor probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logits = tf.layers.dense(inputs=final_state[num_layers-1], \n",
    "                         units=2,\n",
    "                         kernel_initializer=tf.contrib.slim.xavier_initializer())\n",
    "\n",
    "prediction = tf.argmax(logits, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=tf.one_hot(target_inputs, depth=2, dtype=tf.float32),\n",
    "    logits=logits\n",
    ")\n",
    "\n",
    "#loss function\n",
    "loss = tf.reduce_mean(stepwise_cross_entropy)\n",
    "#train it \n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * 단순하게 input sequence의 가장 첫번째 값이 5보다 작으면 False (0), 5 이상이면 True (1) 라고 하자.\n",
    " * next_feed function은 input sequence를 3~8사이의 길이로 무작위 0~9 값을 채워 넣는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def next_feed():\n",
    "    batch = next(batches)\n",
    "    inputs_, input_lengths_ = helpers.batch(batch)\n",
    "    inputs_ = inputs_.T\n",
    "    target_inputs_, _ = helpers.batch([np.append(sequence, [1]) for sequence in batch])\n",
    "#     helpers.batch([np.append(sequence, [1]) for sequence in batch])\n",
    "#     helpers.batch([np.append(sequence[::-1], [1], axis=0) for sequence in batch])\n",
    "    \n",
    "    \n",
    "    target_inputs_ = map(lambda x: [0] if x<5 else [1], target_inputs_.T[:,0:1])\n",
    "#     print(np.shape(decoder_targets_))\n",
    "    return {\n",
    "        inputs: inputs_,\n",
    "        inputs_length: input_lengths_,\n",
    "        target_inputs: target_inputs_\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 0.678828060627\n",
      "  sample 1:\n",
      "    input     > [6 4 8 0 0 0 0 0]\n",
      "    predicted > 0\n",
      "  sample 2:\n",
      "    input     > [7 9 4 2 5 0 0 0]\n",
      "    predicted > 0\n",
      "  sample 3:\n",
      "    input     > [8 4 5 8 6 8 2 3]\n",
      "    predicted > 1\n",
      "()\n",
      "batch 1000\n",
      "  minibatch loss: 0.000183060852578\n",
      "  sample 1:\n",
      "    input     > [5 4 3 0 0 0 0 0]\n",
      "    predicted > 1\n",
      "  sample 2:\n",
      "    input     > [8 9 3 9 0 0 0 0]\n",
      "    predicted > 1\n",
      "  sample 3:\n",
      "    input     > [2 4 0 2 1 6 2 0]\n",
      "    predicted > 0\n",
      "()\n",
      "batch 2000\n",
      "  minibatch loss: 4.81309107272e-05\n",
      "  sample 1:\n",
      "    input     > [9 9 6 2 0 1 4 3]\n",
      "    predicted > 1\n",
      "  sample 2:\n",
      "    input     > [4 0 5 7 2 0 0 0]\n",
      "    predicted > 0\n",
      "  sample 3:\n",
      "    input     > [4 9 5 8 0 0 0 0]\n",
      "    predicted > 0\n",
      "()\n",
      "batch 3000\n",
      "  minibatch loss: 2.01159018616e-05\n",
      "  sample 1:\n",
      "    input     > [1 5 9 4 0 0 0 0]\n",
      "    predicted > 0\n",
      "  sample 2:\n",
      "    input     > [3 9 0 5 4 9 2 0]\n",
      "    predicted > 0\n",
      "  sample 3:\n",
      "    input     > [6 4 1 0 0 0 0 0]\n",
      "    predicted > 1\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "max_batches = 3001\n",
    "batches_in_epoch = 1000\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "loss_track = []\n",
    "try:\n",
    "    for batch in range(max_batches):\n",
    "        fd = next_feed()\n",
    "        _, l = sess.run([train_op, loss], fd)\n",
    "        loss_track.append(l)\n",
    "\n",
    "        if batch == 0 or batch % batches_in_epoch == 0:\n",
    "            print('batch {}'.format(batch))\n",
    "            print('  minibatch loss: {}'.format(sess.run(loss, fd)))\n",
    "            predict_ = sess.run(prediction, fd)\n",
    "            for i, (inp, pred) in enumerate(zip(fd[inputs], predict_)):\n",
    "                print('  sample {}:'.format(i + 1))\n",
    "                print('    input     > {}'.format(inp))\n",
    "                print('    predicted > {}'.format(pred))\n",
    "                if i >= 2:\n",
    "                    break\n",
    "            print()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('training interrupted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.0000201374 after 300100 examples (batch_size=100)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0224c0c910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_track)\n",
    "print('loss {:.10f} after {} examples (batch_size={})'.format(loss_track[-1], len(loss_track)*batch_size, batch_size))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow-gpu",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
